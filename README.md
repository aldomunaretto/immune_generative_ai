# Immune Generative AI

Este repositorio tiene como objetivo introducir los fundamentos de la **Inteligencia Artificial Generativa (GenAI)** y proporcionar una guÃ­a prÃ¡ctica para trabajar con **Modelos de Lenguaje de Gran TamaÃ±o (LLMs)** usando herramientas de cÃ³digo abierto como **Ollama**.

---

## ğŸ“‘ Ãndice de Contenido

- [ğŸ§  Â¿QuÃ© es la Inteligencia Artificial Generativa?](#-quÃ©-es-la-inteligencia-artificial-generativa)
- [ğŸ“š Â¿QuÃ© son los LLMs?](#-quÃ©-son-los-llms)
- [ğŸ¢ Proveedores Comerciales de LLMs](#-proveedores-comerciales-de-llms)
- [ğŸŒ Modelos de CÃ³digo Abierto (actualizado 2025)](#-modelos-de-cÃ³digo-abierto-actualizado-2025)
- [ğŸ“ Context Engineering](#-context-engineering)
- [ğŸ¯ Fine-tuning](#-fine-tuning)
- [ğŸ“‚ Retrieval-Augmented Generation (RAG)](#-retrieval-augmented-generation-rag)
- [ğŸ§ª EvaluaciÃ³n y MÃ©tricas](#-evaluaciÃ³n-y-mÃ©tricas)
- [ğŸ” Seguridad, AlineaciÃ³n y Riesgos](#-seguridad-alineaciÃ³n-y-riesgos)
- [ğŸ’° OptimizaciÃ³n de Costos](#-optimizaciÃ³n-de-costos)
- [ğŸ›°ï¸ Observabilidad y Trazabilidad](#-observabilidad-y-trazabilidad)
- [ğŸ§ª Testing de Prompts](#-testing-de-prompts)
- [ğŸ§µ GestiÃ³n de Contexto Extendido](#-gestiÃ³n-de-contexto-extendido)
- [ğŸ›£ï¸ Roadmap de Aprendizaje Sugerido](#ï¸-roadmap-de-aprendizaje-sugerido)
- [ğŸ¤— Hugging Face](#-hugging-face)
- [ğŸ§° Ollama](#-ollama)
- [ğŸ–¥ï¸ LM Studio](#-lm-studio)
- [ğŸ§© AnythingLLM](#-anythingllm)
- [ğŸ“š Msty](#-msty)
- [ğŸŒ Gradio](#-gradio)
- [ğŸ“Š Streamlit](#-streamlit)
- [ğŸ—£ï¸ ElevenLabs](#ï¸-elevenlabs)
- [ğŸ”— Recursos adicionales](#-recursos-adicionales)

---

## ğŸ§  Â¿QuÃ© es la Inteligencia Artificial Generativa?

La **IA Generativa** es un campo de la inteligencia artificial que se centra en la creaciÃ³n de contenido nuevo y original a partir de datos existentes. Esto incluye texto, imÃ¡genes, cÃ³digo, mÃºsica, video y mÃ¡s. Su auge reciente se debe al desarrollo de modelos de deep learning capaces de generar resultados sorprendentes en tareas creativas y cognitivas.

---

## ğŸ“š Â¿QuÃ© son los LLMs?

Los **Large Language Models (LLMs)** son redes neuronales entrenadas con grandes cantidades de texto para aprender patrones del lenguaje humano. Estos modelos pueden:

- Generar texto coherente
- Resumir documentos
- Traducir entre idiomas
- Contestar preguntas
- Escribir cÃ³digo, entre muchas otras tareas.

---

## ğŸ¢ Proveedores Comerciales de LLMs

A continuaciÃ³n se listan algunos de los principales proveedores que ofrecen LLMs accesibles mediante API o servicios cloud:

| Proveedor       | Modelos Destacados (2026)                              | Plataforma/API                   | Notas |
|-----------------|--------------------------------------------------------|----------------------------------|-------|
| **OpenAI**      | GPT-5.2, o3, o1-pro, GPT-4o                            | https://platform.openai.com      | Soporte multimodal, Realtime API |
| **Anthropic**   | Claude 4.5 Opus (Thinking), Claude 4 Sonnet            | https://www.anthropic.com        | Foco en seguridad. Excelente en matices lingÃ¼Ã­sticos y razonamiento complejo con modo "Thinking". |
| **Google**      | Gemini 3 Pro / Nano Banana / Veo3                      | https://ai.google.dev            | Contexto largo, multimodal nativo y foco en razonamiento + agentes. |
| **Meta**        | Llama 4 Scout, Llama 4 Maverick (pesos + API)          | https://ai.meta.com/llama        | â€œOpen-weightâ€ (con condiciones de licencia), opciÃ³n de self-hosting + acceso vÃ­a API.|
| **Alibaba**     | Qwen3 (familia), Qwen3-Max, (lÃ­nea Qwen3-Next)         | https://qwenlm.github.io         | Mucho empuje en modelos â€œhybrid reasoningâ€ y escalado; Max aparece como tope de gama.|
| **DeepSeek AI** | DeepSeek-V3.2, DeepSeek-R1                             | https://deepseekcoder.github.io  | Enfocado en razonamiento/cÃ³digo con releases frecuentes (V3.x) y lÃ­nea R1. Especializado en cÃ³digo. |
| **Mistral**     | Mistral Large 3, Mistral 3 (14B/8B/3B)                 | https://mistral.ai               | Oferta muy sÃ³lida en open models + opciones enterprise; nueva generaciÃ³n â€œMistral 3â€.|
| **Cohere**      | Command A, Command R / R+.                             | https://cohere.com               | Orientado a enterprise + RAG + tool use; Cohere recomienda Command A como â€œlatestâ€ frente a R+. |
| **AWS (Bedrock)**      | Amazon Nova (Premier/Pro/Lite/Micro), + Titan (embeddings / image / legacy text)   | https://aws.amazon.com/bedrock   | Nova es la lÃ­nea moderna multimodal/agentic; Titan sigue presente (especialmente embeddings/imÃ¡genes) y parte de text se migra hacia Nova.|
| **xAI** | Grok 4, Grok 3 | https://docs.x.ai/ | API con modelos versionados/aliases; Grok 4 aparece como oferta actual. |
| **AI21 Labs** | Jamba, Jamba2| https://docs.ai21.com/ | Modelos basados en la lÃ­nea Claude, con enfoque en NLP avanzado. |

### ğŸš€ Tendencias Clave de 2026
- Modelos de Razonamiento (Reasoning): Ya no solo predicen la siguiente palabra; modelos como o3 o Claude 4.5 Thinking utilizan "cadena de pensamiento" interna antes de responder, lo que reduce drÃ¡sticamente las alucinaciones en tareas lÃ³gicas.
- Agentes Nativos: La mayorÃ­a de los modelos actuales (especialmente Llama 4 y GPT-5.2) estÃ¡n diseÃ±ados para usar herramientas de forma autÃ³noma, permitiendo crear flujos de trabajo sin intervenciÃ³n humana constante.
- Eficiencia Extrema: Los modelos "Small" o "Flash" de 2026 son hoy mÃ¡s potentes de lo que era GPT-4 en su lanzamiento, permitiendo inferencia local en dispositivos con gran precisiÃ³n.

---

## ğŸŒ Modelos de CÃ³digo Abierto (actualizado 2025)

A continuaciÃ³n se listan algunos de los LLMs open source mÃ¡s destacados y actualizados:

| Modelo           | Autor/OrganizaciÃ³n | TamaÃ±os Disponibles | VersiÃ³n Actual | Licencia      |
|------------------|--------------------|----------------------|----------------|----------------|
| **LLaMA**        | Meta               | 8B, 70B              | LLaMA 4        | Meta RAIL      |
| **Qwen**         | Alibaba            | 0.5B a 110B          | Qwen 2         | Apache 2.0     |
| **DeepSeek**     | DeepSeek AI        | 1.3B a 236B          | DeepSeek-V2    | MIT            |
| **Phi**          | Microsoft          | 3.8B, 7B             | Phi-3          | MIT            |
| **Gemma**        | Google             | 2B, 7B               | Gemma 1.1      | Apache 2.0     |
| **Mistral**      | Mistral AI         | 7B, Mixtral (12.7B MoE) | Mistral 7B / Mixtral 8x7B | Apache 2.0 |
| **Falcon**       | TII (UAE)          | 7B, 180B             | Falcon 180B    | Apache 2.0     |
| **Command-R**    | Cohere             | 35B                  | Command-R+     | RAIL           |

---

## ğŸ“ Prompt Engineering

La ingenierÃ­a de prompts (Prompt Engineering) es el arte y la ciencia de diseÃ±ar entradas (prompts) para LLMs con el fin de obtener salidas mÃ¡s precisas, seguras y previsibles sin alterar los pesos del modelo. Combina diseÃ±o de instrucciones, estructuraciÃ³n del contexto, selecciÃ³n de ejemplos y restricciones de formato para alinear la respuesta con requisitos funcionales y de negocio.

TÃ©cnicas comunes
- Mensajes de sistema/rol: separar instrucciones de alto nivel (system) de la peticiÃ³n del usuario.
- Zeroâ€‘shot vs Fewâ€‘shot: proporcionar 0 o varios ejemplos para guiar estilo y formato.
- Prompt templates: plantillas parametrizables y versionadas.
- Constraints estructurales: schema JSON, regex o formatos esperados para validar salidas.
- Temperature / sampling: controlar creatividad vs determinismo.
- Chain-of-Thought (CoT) y pasos intermedios: usar pasos explicativos controlados para tareas de razonamiento (con precauciÃ³n).
- Toolâ€‘use / function calling: definir llamadas a herramientas y formatos de intercambio.
- Robustness: testear contra prompt injection y entradas adversarias.

Ejemplos prÃ¡cticos

- Zeroâ€‘shot (instrucciÃ³n clara)
```
System: Eres un redactor tÃ©cnico conciso.
User: Resume el siguiente texto en 3 bullets con lenguaje para ejecutivos.
[DOCUMENTO...]
```

- Fewâ€‘shot (estilo y formato)
```
User: Ejemplo 1:
Input: Â¿QuÃ© es X?
Output: X es... (1-2 frases)

User: Ejemplo 2:
Input: CÃ³mo configurar Y?
Output: 1) Paso A 2) Paso B

User: Ahora haz lo mismo para: [nueva pregunta]
```

- Output estructurado (JSON schema)
```
System: Responde SOLO en JSON con campos: { "summary": string, "impact": "low|medium|high", "actions": [string] }
User: Resume este informe y sugiere acciones.
[INFORME...]
```

- Role play / persona
```
System: Eres un analista de seguridad con 10 aÃ±os de experiencia.
User: Identifica 3 riesgos clave y una mitigaciÃ³n por cada uno.
```

Buenas prÃ¡cticas breves
- Definir rol, objetivo, audiencia y formato (ROCE).
- Proveer ejemplos representativos y contraejemplos.
- Validar y testear con mutaciones adversarias.
- Versionar templates y registrar prompt final utilizado en producciÃ³n.
- Preferir restricciones estructurales (JSON schema) en lugar de solo instrucciones abiertas.

Lecturas y herramientas
- [Prompt Engineering Guide](https://promptingguide.ai/)
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models â€” Wei et al.](https://arxiv.org/pdf/2201.11903)
- [Rebuff: Detecting Prompt Injection Attacks](https://www.blog.langchain.com/rebuff/)
- [Guidance](https://github.com/guidance-ai/guidance)
- [Promptfoo: LLM evals & red teaming](https://github.com/promptfoo/promptfoo)

Referencias rÃ¡pidas
- Guidance, Promptfoo, Promptify â€” utilidades para crear, testar y versionar prompts.


### ROCE â€” Framework para diseÃ±ar prompts

ROCE es un acrÃ³nimo que resume cuatro elementos clave para construir prompts claros y efectivos al interactuar con LLMs:

- R â€” Rol: indica la perspectiva o identidad del modelo (p. ej. "Eres un analista de seguridad senior").
- O â€” Objetivo: define la meta concreta del prompt (p. ej. "Resumir los riesgos en 3 puntos accionables").
- C â€” Contexto: aporta datos relevantes, restricciones y cualquier informaciÃ³n necesaria (documentos, formato, audiencia).
- E â€” Ejemplo: muestra ejemplos de entrada/salida o el formato deseado para guiar la respuesta.

Por quÃ© usar ROCE:
- Aumenta la precisiÃ³n y relevancia de las respuestas.
- Reduce ambigÃ¼edad y alucinaciones.
- Facilita respuestas con formato predecible y verificable.

Plantilla rÃ¡pida:

```
# ROLE
Eres un [profesiÃ³n/experto] con [N aÃ±os] de experiencia en [Ã¡rea].
Tu especialidad es [skill especÃ­fico].

# OBJECTIVE
Tu tarea es [acciÃ³n especÃ­fica] que cumpla:
- [Criterio 1 de Ã©xito]
- [Criterio 2 de Ã©xito]
- [Criterio 3 de Ã©xito]

# CONTEXT
- Audiencia: [descripciÃ³n detallada]
- Formato: [estructura especÃ­fica]
- Tono: [estilo de comunicaciÃ³n]
- Restricciones: [lÃ­mites claros]
- NO hacer: [prohibiciones explÃ­citas]

# EXAMPLE
[Muestra concreta del output deseado]
```

Consejos prÃ¡cticos:
- SÃ© explÃ­cito y conciso en cada elemento.
- Proporciona ejemplos representativos.
- Itera: refina rol, contexto o ejemplos si la salida no coincide con lo esperado.
- CombÃ­nalo con tÃ©cnicas como few-shot, instrucciones de sistema y constraints (JSON schema, lÃ­mites de tokens) para mayor robustez.

---

## ğŸ“ Context Engineering

El **Context Engineering** consiste en diseÃ±ar cuidadosamente los *prompts* y la informaciÃ³n de entrada para optimizar las respuestas de un LLM sin necesidad de modificar sus pesos. 
Se centra en:
- EstructuraciÃ³n de *prompts* y *templates*.
- InserciÃ³n de *context windows* con ejemplos o instrucciones previas.
- Uso de tÃ©cnicas como **Chain-of-Thought (CoT)**, **Few-Shot Prompting** y **ReAct**.

ğŸ“– **Lecturas sobre Context Engineering**:
- [A Survey of Context Engineering for Large Language Models](https://arxiv.org/abs/2507.13334)
- [Context Rot: How Increasing Input Tokens Impacts LLM Performance](https://research.trychroma.com/context-rot)
- [How Long Contexts Fail](https://www.dbreunig.com/2025/06/22/how-contexts-fail-and-how-to-fix-them.html)
- [Why â€œContext Engineeringâ€ Matters](https://www.dbreunig.com/2025/07/24/why-the-term-context-engineering-matters.html)
- [Context Engineering for Agents](https://blog.langchain.com/context-engineering-for-agents/)
- [Optimizing LangChain AI Agents with Contextual Engineering](https://levelup.gitconnected.com/optimizing-langchain-ai-agents-with-contextual-engineering-0914d84601f3)
- [Prompt Injection Exploits](https://blog.langchain.dev) (riesgos)
- [Evaluation Harness for Prompts](https://github.com) (buscar frameworks)

ğŸ”§ **LibrerÃ­as comunes**:
- [DSPy](https://dspy.ai/) (Framework para context engineering basado en programas declarativos)
    - [ğŸ™ GitHub Repository](https://github.com/stanfordnlp/dspy) 
- [Guidance](https://github.com/microsoft/guidance)
- [Promptify](https://github.com/promptslab/Promptify)
- [Promptfoo (testing)](https://github.com/promptfoo/promptfoo)

---

## ğŸ¯ Fine-tuning

El **Fine-tuning** es el proceso de ajustar los parÃ¡metros de un modelo previamente entrenado usando un conjunto de datos especÃ­fico para una tarea concreta. 
Se utiliza para:
- Mejorar rendimiento en dominios especializados.
- Adaptar el estilo o formato de salida.
- Crear *instruction-tuned models* para casos concretos.

### ğŸ”§ LibrerÃ­as y frameworks:
- [Hugging Face Transformers](https://huggingface.co/transformers)
- [PEFT](https://github.com/huggingface/peft) (Parameter Efficient Fine-Tuning)
- [LoRA](https://github.com/microsoft/LoRA)
- [QLoRA: Efficient Finetuning of Quantized LLMs](https://arxiv.org/abs/2305.14314)
- [TRL (Transformer Reinforcement Learning)](https://github.com/huggingface/trl)
- [H2O LLM Studio](https://github.com/h2oai/h2o-llmstudio)
- [ğŸ¦¥ Unsloth](https://unsloth.ai/) (Framework optimizado para fine-tuning rÃ¡pido y eficiente)
    - [ğŸ™ GitHub Repository](https://github.com/unslothai/unsloth)
    - [ğŸ¤— Hugging Face Organization Card](https://huggingface.co/unsloth)
- [ğŸ¦™ LLaMA-Factory](https://llamafactory.readthedocs.io/en/latest/)
    - [ğŸ™ GitHub Repository](https://github.com/hiyouga/LLaMA-Factory)

### ğŸª¢ Datasets para entrenamiento y ajuste fino (Fine-Tuning) de LLMs:
- [The Pile](https://pile.eleuther.ai/)
- [HelpSteer: Helpfulness SteerLM Dataset](https://huggingface.co/datasets/nvidia/HelpSteer)
- [No Robots](https://huggingface.co/datasets/HuggingFaceH4/no_robots)
- [Anthropic_HH_Golden](https://huggingface.co/datasets/Unified-Language-Model-Alignment/Anthropic_HH_Golden)
- [Trelis Function Calling Dataset](https://huggingface.co/datasets/Trelis/function_calling_extended)
- [Dolma](https://huggingface.co/datasets/allenai/dolma)
- [Open-Platypus](https://huggingface.co/datasets/garage-bAInd/Open-Platypus)
- [Puffin](https://huggingface.co/datasets/LDJnr/Puffin)
- [Alpaca](https://huggingface.co/datasets/tatsu-lab/alpaca)
  - [ğŸ™ GitHub Repository](https://github.com/tatsu-lab/stanford_alpaca)

### ğŸ“„ Formatos para Fine Tuning: Alpaca vs ShareGPT

Los formatos **Alpaca** y **ShareGPT** son los mÃ¡s utilizados para el fineâ€‘tuning supervisado de LLMs, especialmente con frameworks como **LLaMAâ€‘Factory** y **Unsloth**.

#### ğŸ§ª Formato Alpaca

ğŸ“‚ Estructura tÃ­pica (JSON)

```json
{
  "instruction": "...",    
  "input": "...",          
  "output": "...",         
  "system": "...",         
  "history": [             
    ["instrucciÃ³n anterior", "respuesta anterior"]
  ]
}
```

- `instruction`: Pregunta o instrucciÃ³n del humano (requerido).
- `input`: Contexto adicional (opcional).
- `output`: Respuesta esperada del modelo (requerido).
- `system`: Mensaje del sistema (opcional).
- `history`: Rondas anteriores en conversaciones multironda (opcional).

##### âœ… Ventajas
- Muy simple y ampliamente adoptado.
- Ideal para datasets de instrucciÃ³n-respuesta de una sola ronda.

##### âš ï¸ Limitaciones
- No tiene estructura nativa para roles mÃºltiples o multironda avanzada.
- Se apoya en tokens de separaciÃ³n (`###` o EOS).


#### ğŸ§µ ShareGPT

##### ğŸ“‚ Estructura tÃ­pica (JSON)

```json
{
  "conversations": [
    { "from": "human", "value": "â€¦instrucciÃ³n humanaâ€¦" },
    { "from": "gpt",   "value": "â€¦respuesta del modeloâ€¦" },
    { "from": "function_call", "value": "â€¦argumentos de herramientaâ€¦" },
    { "from": "observation",   "value": "â€¦resultado de herramientaâ€¦" }
  ],
  "system": "...",
  "tools": "..."
}
```

- Permite mÃºltiples roles: `human`, `gpt`, `function_call`, `observation`.
- DiseÃ±ado para conversaciones multironda y llamadas a funciones.

##### âœ… Ventajas
- Soporta roles y contextos complejos.
- Ideal para datasets de diÃ¡logo real y herramientas.

##### âš ï¸ Limitaciones
- MÃ¡s complejo de preparar que Alpaca Format.


#### ğŸ“¦ Soporte en Frameworks

- **LLaMAâ€‘Factory**: Soporta ambos formatos mediante configuraciÃ³n en `dataset_info.json`.
- **Unsloth**:
  - Permite convertir con `standardize_sharegpt()`.
  - Ofrece `conversation_extension` para simular multironda desde Alpaca.


#### ğŸ“Š Comparativa RÃ¡pida

| Aspecto                  | Alpaca Format                         | ShareGPT Format                              |
|--------------------------|----------------------------------------|----------------------------------------------|
| InstrucciÃ³n + respuesta  | âœ…                                    | âœ…                                           |
| Multi-turno              | âš ï¸ Opcional, sin estructura fija       | âœ… Nativo                                    |
| Roles adicionales        | âŒ                                     | âœ… function_call, observation, etc.          |
| Complejidad              | ğŸ”¹ Baja                               | ğŸ”¹ Media-Alta                                |
| ConversiÃ³n disponible    | ğŸ”¸ Limitada                            | âœ… Via Unsloth                               |


#### ğŸ§  Â¿CuÃ¡l elegir?

- **Alpaca** â†’ Para datasets simples de instrucciones/respuestas.
- **ShareGPT** â†’ Para diÃ¡logos multironda, roles mÃºltiples y escenarios con herramientas.

#### ğŸ“„ Lecturas:

- [How to create a custom Alpaca instruction dataset for fine-tuning LLMs](https://zackproser.com/blog/how-to-create-a-custom-alpaca-dataset)

---

## ğŸ“‚ Retrieval-Augmented Generation (RAG)

El **RAG** combina la generaciÃ³n de texto con la recuperaciÃ³n de informaciÃ³n externa en tiempo real. 
En lugar de confiar solo en el conocimiento interno del LLM, **recupera documentos relevantes** y los pasa como contexto al modelo antes de generar la respuesta.

ğŸ”§ **LibrerÃ­as comunes**:
- [LangChain](https://www.langchain.com/)
- [LangGraph](https://www.langgraph.dev/) 
- [LlamaIndex](https://www.llamaindex.ai/)
- [Haystack](https://haystack.deepset.ai/)
- [Pinecone](https://www.pinecone.io/) (vector DB)
- [Weaviate](https://weaviate.io/) (vector DB)
- [Chroma](https://www.trychroma.com/) (vector DB)

**Casos de uso**:
- Chatbots empresariales con documentos privados.
- BÃºsqueda semÃ¡ntica combinada con LLMs.
- Sistemas de soporte y asistencia con informaciÃ³n actualizada.

**Estrategias avanzadas:**
- Hybrid Search (BM25 + vector)
- Re-rankers (Cross-Encoder, ColBERT)
- Chunking adaptativo (basado en densidad semÃ¡ntica)
- Caching semÃ¡ntico (embedding cache)
- Context compression (resÃºmenes jerÃ¡rquicos)

---

## ğŸ§ª EvaluaciÃ³n y MÃ©tricas

La evaluaciÃ³n consistente evita regresiones.

Tipos:
- AutomÃ¡tica: BLEU, ROUGE (limitado), BERTScore, COMET.
- Basada en LLM-as-a-Judge: pares A/B, escalas Likert.
- MÃ©tricas especÃ­ficas: 
  - Context hit rate (RAG)
  - Hallucination rate
  - Latencia P50/P95/P99
  - Costo por 1K tokens Ãºtiles
  - Tasa de tool success (agentes)

Herramientas:
- [lm-eval-harness](https://github.com/EleutherAI/lm-evaluation-harness)
- [Gaia / MMLU / GSM8K] (benchmarks)
- [Promptfoo](https://github.com/promptfoo/promptfoo)
- [WeightWatcher] (calidad modelos)

---

## ğŸ” Seguridad, AlineaciÃ³n y Riesgos

Aspectos:
- Prompt Injection
- Data Exfiltration
- Jailbreaks
- Leakage de PII
- Output Filtering / Red Teaming

Mitigaciones:
- SanitizaciÃ³n de entradas
- SeparaciÃ³n de roles (system vs user)
- Clasificadores de seguridad (moderation endpoints)
- Guardrails: [NeMo Guardrails], [Guardrails-AI], [Azure Content Filters]

---

## ğŸ’° OptimizaciÃ³n de Costos

Estrategias:
- Seleccionar modelo por tarea (routing / cascadas)
- CuantizaciÃ³n local (4-bit, QLoRA)
- Prompt trimming y compresiÃ³n semÃ¡ntica
- Reutilizar embeddings (cache)
- Streaming parcial
- Batch inference

KPIs:
- Tokens por intenciÃ³n
- Tokens contextuales redundantes
- Costo por sesiÃ³n resuelta

---

## ğŸ›°ï¸ Observabilidad y Trazabilidad

QuÃ© capturar:
- Prompt final compilado
- Versionado de plantillas
- Latencia end-to-end
- Tool calls y resultados
- Evaluaciones post-hoc

Herramientas:
- [LangSmith], [Weights & Biases], [Arize](https://arize.com), [Helicone], [E2B sandbox], [PromptLayer]

---

## ğŸ§ª Testing de Prompts

Tipos:
- RegresiÃ³n (snapshot expected outputs)
- Sensibilidad (mutaciones adversarias)
- Robustez (ruido / reorder)
- Factualidad (verificador externo)

Pipeline:
1. Dataset representativo
2. DefiniciÃ³n de aserciones (regex, JSON schema, LLM judge)
3. Score agregado (>= umbral)
4. Gate CI/CD

---

## ğŸ§µ GestiÃ³n de Contexto Extendido

TÃ©cnicas:
- Chunking semÃ¡ntico adaptativo
- ResÃºmenes jerÃ¡rquicos (map â†’ reduce â†’ refine)
- Sliding window + focal retrieval
- Embedding + graph enrichment
- Long-context distillation (partial fine-tune)

Riesgos: context rot, diluciÃ³n de seÃ±al, latencia.

---

## ğŸ›£ï¸ Roadmap de Aprendizaje Sugerido

1. Fundamentos: prompts + inferencia local (Ollama)
2. RAG bÃ¡sico
3. EvaluaciÃ³n y mÃ©tricas
4. Fine-tuning PEFT
5. Tool use / agentes
6. OptimizaciÃ³n costo-rendimiento
7. Observabilidad + seguridad
8. OrquestaciÃ³n avanzada (LangGraph / DSPy)

---

## ğŸ¤— Hugging Face

[Hugging Face](https://huggingface.co/) es una de las plataformas mÃ¡s influyentes en el ecosistema de inteligencia artificial moderna. Su propÃ³sito es democratizar el acceso a modelos de IA, datasets y herramientas para investigaciÃ³n, desarrollo y despliegue de soluciones basadas en machine learning.

**Â¿QuÃ© ofrece Hugging Face?**
- Un *hub centralizado* de modelos entrenados y datasets etiquetados.
- LibrerÃ­as como `transformers`, `datasets`, `peft`, `diffusers` y `evaluate`.
- Espacios (*Spaces*) para ejecutar y compartir demos interactivas.
- La Hugging Face Hub API para integrar modelos en producciÃ³n.
- Herramientas de fine-tuning, inferencia, cuantizaciÃ³n y mÃ¡s.
- Una comunidad colaborativa activa de investigadores, empresas y desarrolladores.

**Usos comunes:**
- Integrar LLMs como LLaMA, Mistral o Phi en apps.
- Entrenar modelos personalizados.
- Evaluar y comparar arquitecturas de IA.
- Desplegar servicios de inferencia desde Hugging Face Inference Endpoints.
- Explorar nuevos modelos generativos, como Diffusion Models para imagen y audio.

---

## ğŸ§° Ollama

[**Ollama**](https://ollama.com) es una herramienta sencilla para ejecutar modelos LLM localmente, con soporte para mÃºltiples modelos open-source preconfigurados.

### Requisitos

- macOS, Linux o Windows (con soporte WSL)
- Docker NO es necesario
- CPU moderna o GPU con soporte para aceleraciÃ³n (opcional)

### ğŸ“– DocumentaciÃ³n y APIs

- [Repositorio de GitHub](https://github.com/ollama/ollama)
- [DocumentaciÃ³n oficial de Ollama](https://github.com/ollama/ollama/tree/main/docs)
- [GuÃ­a de la API de Ollama](../../wiki/ollama_api)  
- [SDK de Python para Ollama](../../wiki/ollama_python_sdk)
- [CreaciÃ³n y uso de Modelfile en Ollama](../../wiki/ollama_modelfile)

---

## ğŸ–¥ï¸ LM Studio

[LM Studio](https://lmstudio.ai/) es una aplicaciÃ³n de escritorio que permite interactuar con modelos de lenguaje de manera local y visual. Funciona como una interfaz grÃ¡fica para Ollama y llama.cpp, y estÃ¡ pensada para usuarios no tÃ©cnicos o que prefieren una experiencia similar a ChatGPT, pero con modelos locales.

**CaracterÃ­sticas destacadas:**
- Descargar y ejecutar modelos directamente desde la app.
- Soporte para mÃºltiples modelos open-source (LLaMA, Mistral, Phi, etc.).
- PersonalizaciÃ³n de temperatura, longitud de respuesta y formato.
- Compatible con macOS, Windows y Linux.

Ideal para experimentaciÃ³n, redacciÃ³n de contenido, aprendizaje y evaluaciÃ³n rÃ¡pida de modelos sin escribir cÃ³digo.

---

## ğŸ§© AnythingLLM

[AnythingLLM](https://anythingllm.com/) es una plataforma de cÃ³digo abierto que permite crear un **asistente privado impulsado por LLMs**, capaz de trabajar con tus propios datos, documentos y fuentes de conocimiento.  
[ğŸ™ GitHub Repository](https://github.com/Mintplex-Labs/anything-llm)

**Â¿QuÃ© puedes hacer con AnythingLLM?**
- Subir archivos (PDF, DOCX, TXT, etc.) y hacer preguntas sobre su contenido.
- Conectar fuentes externas como Notion, GitHub repos, sitios web y mÃ¡s.
- Utilizar diferentes backends como OpenAI, Ollama, Mistral, Hugging Face, entre otros.
- Desplegarlo en local, en servidores personales o en la nube.
- Administrar mÃºltiples espacios y usuarios con control de acceso.

Una soluciÃ³n ideal para construir un **chat corporativo privado**, motores de bÃºsqueda internos o asistentes personales de conocimiento con arquitectura plug-and-play.

---

## ğŸ“š Msty

[Msty](https://msty.app/) es una herramienta especializada en la **visualizaciÃ³n y anÃ¡lisis interno** de modelos de lenguaje.  
[ğŸ™ GitHub Repository](https://github.com/linonetwo/msty)

Te permite explorar:
- **Tokens** generados en cada paso
- **Embeddings** vectoriales y distancias semÃ¡nticas
- **Probabilidades de predicciÃ³n** token a token

Ideal para investigadores, educadores y quienes quieren entender cÃ³mo "piensa" un modelo. Msty puede ayudarte a explicar errores, mejorar prompts o hacer debugging de outputs inesperados.

---

## ğŸŒ Gradio

[Gradio](https://www.gradio.app/) es una librerÃ­a de Python que permite construir interfaces web para modelos de machine learning y deep learning en minutos. Ideal para prototipos, demos y validaciÃ³n con usuarios.

**Usos principales:**
- Crear formularios o chatbots con LLMs.
- Visualizar outputs de modelos de imagen, audio o NLP.
- Integrar con Hugging Face Spaces o notebooks.

Con unas pocas lÃ­neas de cÃ³digo puedes desplegar una interfaz intuitiva y compartible con cualquier persona.

---

## ğŸ“Š Streamlit

[Streamlit](https://streamlit.io) es un framework en Python para crear **aplicaciones web interactivas de forma rÃ¡pida**, ideal para prototipar interfaces con modelos de IA.

### ğŸ”§ CaracterÃ­sticas clave
- Interfaz muy sencilla basada en Python puro (sin necesidad de HTML/CSS/JS).
- Ideal para dashboards, demos de modelos y visualizaciÃ³n de datos.
- IntegraciÃ³n directa con librerÃ­as como `pandas`, `plotly`, `matplotlib` y APIs de LLMs.
- Permite desplegar aplicaciones fÃ¡cilmente en la nube mediante [Streamlit Community Cloud](https://streamlit.io/cloud).

---

## ğŸ—£ï¸ ElevenLabs

[ElevenLabs](https://elevenlabs.io) es una plataforma lÃ­der en **generaciÃ³n de voz mediante IA**.  
Permite crear voces sintÃ©ticas realistas en mÃºltiples idiomas y estilos, siendo ampliamente usada para aplicaciones de:

- **NarraciÃ³n de audiolibros y podcasts.**
- **GeneraciÃ³n de diÃ¡logos en videojuegos.**
- **ConversiÃ³n de texto a voz (TTS) en asistentes virtuales.**
- **CreaciÃ³n de personajes con voces personalizadas.**

### ğŸ”§ CaracterÃ­sticas clave
- Modelos de voz de alta fidelidad y expresividad.
- Soporte multilingÃ¼e y clonaciÃ³n de voz.
- API sencilla para integraciones en aplicaciones web y mÃ³viles.
- Planes de uso gratuito y de pago segÃºn volumen de caracteres.

### ğŸ“š LibrerÃ­as y SDKs
- [ElevenLabs Python SDK](https://pypi.org/project/elevenlabs/)
- API REST para integraciÃ³n con cualquier lenguaje.
- Plugins y conectores para aplicaciones de contenido multimedia.

---

## ğŸ”— Recursos adicionales

### ğŸ“š DocumentaciÃ³n y Comparativas

- [ğŸ¤— Hugging Face Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) â€“ Comparativa actualizada de modelos open-source.
- [ğŸ¤— Hugging Face Hub](https://huggingface.co/models) â€“ Repositorio central de modelos preentrenados y datasets para IA generativa, NLP, visiÃ³n y mÃ¡s.
- [ğŸ¤— Hugging Face Trending Papers](https://huggingface.co/papers/trending) - Lista de papers recientes en IA y machine learning.
- [ğŸ“ The Gradient](https://thegradient.pub/) â€“ ArtÃ­culos y anÃ¡lisis sobre LLMs.
- [ğŸ§  Awesome LLM](https://github.com/Hannibal046/Awesome-LLM) â€“ Lista curada de modelos, datasets y herramientas.

### âš™ï¸ Frameworks y LibrerÃ­as
- [ğŸ“ˆ Pydantic](https://docs.pydantic.dev/latest/) - La librerÃ­a de validaciÃ³n de datos mÃ¡s utilizada en Python
    - [ğŸ™ GitHub Repository](https://github.com/pydantic/pydantic)
- [ğŸ§ª LangChain](https://www.langchain.com/) â€“ OrquestaciÃ³n de agentes y flujos con LLMs, APIs y herramientas externas.
- [ğŸ” LangGraph](https://www.langgraph.dev/) â€“ Framework para flujos conversacionales multiestado con LLMs.
- [ğŸ“¦ LlamaIndex](https://www.llamaindex.ai/) â€“ Framework para crear aplicaciones de RAG (Retrieval-Augmented Generation).
- [ğŸ¤— Transformers (Hugging Face)](https://huggingface.co/docs/transformers/index) â€“ LibrerÃ­a para el uso de modelos de lenguaje en Python.
- [LangSmith](https://www.langchain.com/langsmith) â€“ Observabilidad
- [Helicone](https://www.helicone.ai/) â€“ Logging de llamadas LLM
- [Promptfoo](https://github.com/promptfoo/promptfoo) â€“ Testing de prompts
- [Guardrails AI](https://github.com/guardrails-ai/guardrails) â€“ ValidaciÃ³n estructural
- [NeMo Guardrails](https://github.com/NVIDIA/NeMo-Guardrails) â€“ Seguridad conversacional

### Personas de Interes
- [Jeremy Howard](https://jeremy.fast.ai/)
    - [ğŸ™ GitHub Repository](https://github.com/jph00)
    - [ğŸ™ Fast.ai GitHub Repository](https://github.com/fastai)
    - [fast.aiâ€”Making neural nets uncool again](https://www.fast.ai/)
- [Andrej Karpathy](https://karpathy.ai/)
    - [ğŸ™ GitHub Repository](https://github.com/karpathy)
    - [ğŸ¤— Hugging Face Page](https://huggingface.co/karpathy)
    - X.com: [@karpathy](https://x.com/karpathy)
- [Sebastian Raschka](https://sebastianraschka.com/)
    - X.com: [@rasbt](https://x.com/rasbt)
- [Maxime Labonne](https://mlabonne.github.io/blog/)
    - [ğŸ™ GitHub Repository](https://github.com/mlabonne)
    - [ğŸ¤— Hugging Face Page](https://huggingface.co/mlabonne)
    - [LLM Engineer's Handbook](https://github.com/PacktPublishing/LLM-Engineers-Handbook)
- [Colin Kealty (Bartowski)](https://x.com/bartowski1182)
    - [ğŸ™ GitHub Repository](https://github.com/bartowski1182)
    - [ğŸ¤— Hugging Face Page](https://huggingface.co/bartowski)
    - [ğŸ¤— Hugging Face LM Studio Community Page](https://huggingface.co/lmstudio-community)
- [David Kim](https://x.com/interpreter_ai)
    - [ğŸ™ GitHub Repository](https://github.com/davidkimai)
    - [ğŸ¤— Hugging Face Recursive Labs Page](https://huggingface.co/recursivelabsai)
- [Drew Breunig](https://www.dbreunig.com/)

### Enlaces Ãštiles
- [LLM Visualization](https://bbycroft.net/llm)
- [BertViz Interactive Tutorial](https://colab.research.google.com/drive/1hXIQ77A4TYS4y3UthWF-Ci7V7vVUoxmQ)
- nanoGPT: [ğŸ™ GitHub Repository](https://github.com/karpathy/nanoGPT)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [Attention is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)
- [The GAN Zoo](https://github.com/hindupuravinash/the-gan-zoo)