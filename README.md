# Immune Generative AI

Este repositorio tiene como objetivo introducir los fundamentos de la **Inteligencia Artificial Generativa (GenAI)** y proporcionar una guÃ­a prÃ¡ctica para trabajar con **Modelos de Lenguaje de Gran TamaÃ±o (LLMs)** usando herramientas de cÃ³digo abierto como **Ollama**.

---

## ğŸ“‘ Ãndice de Contenido

- [ğŸ§  Â¿QuÃ© es la Inteligencia Artificial Generativa?](#-quÃ©-es-la-inteligencia-artificial-generativa)
- [ğŸ“š Â¿QuÃ© son los LLMs?](#-quÃ©-son-los-llms)
- [ğŸ¢ Proveedores Comerciales de LLMs](#-proveedores-comerciales-de-llms)
- [ğŸŒ Modelos de CÃ³digo Abierto (actualizado 2025)](#-modelos-de-cÃ³digo-abierto-actualizado-2025)
- [ğŸ¤— Hugging Face](#-hugging-face)
- [ğŸ§° Ollama](#-ollama)
- [ğŸ–¥ï¸ LM Studio](#-lm-studio)
- [ğŸ§© AnythingLLM](#-anythingllm)
- [ğŸ“š Msty](#-msty)
- [ğŸŒ Gradio](#-gradio)
- [ğŸ”— Recursos adicionales](#-recursos-adicionales)

---

## ğŸ§  Â¿QuÃ© es la Inteligencia Artificial Generativa?

La **IA Generativa** es un campo de la inteligencia artificial que se centra en la creaciÃ³n de contenido nuevo y original a partir de datos existentes. Esto incluye texto, imÃ¡genes, cÃ³digo, mÃºsica, video y mÃ¡s. Su auge reciente se debe al desarrollo de modelos de deep learning capaces de generar resultados sorprendentes en tareas creativas y cognitivas.

---

## ğŸ“š Â¿QuÃ© son los LLMs?

Los **Large Language Models (LLMs)** son redes neuronales entrenadas con grandes cantidades de texto para aprender patrones del lenguaje humano. Estos modelos pueden:

- Generar texto coherente
- Resumir documentos
- Traducir entre idiomas
- Contestar preguntas
- Escribir cÃ³digo, entre muchas otras tareas.

---

## ğŸ¢ Proveedores Comerciales de LLMs

A continuaciÃ³n se listan algunos de los principales proveedores que ofrecen LLMs accesibles mediante API o servicios cloud:

| Proveedor       | Modelo Principal            | Plataforma/API                   |
|------------------|-----------------------------|----------------------------------|
| **OpenAI**       | GPT-4o, GPT-4, GPT-3.5       | https://platform.openai.com     |
| **Anthropic**    | Claude 3                    | https://www.anthropic.com       |
| **Google**       | Gemini 1.5                  | https://ai.google.dev           |
| **Meta**         | LLaMA 4                     | https://ai.meta.com/llama       |
| **Alibaba**      | Qwen 2                      | https://qwenlm.github.io        |
| **DeepSeek AI**  | DeepSeek-V2, DeepSeek-Coder | https://deepseekcoder.github.io |
| **Mistral**      | Mistral/Mixtral             | https://mistral.ai               |
| **Cohere**       | Command-R+                  | https://cohere.com               |
| **Amazon**       | Titan                       | https://aws.amazon.com/bedrock  |

---

## ğŸŒ Modelos de CÃ³digo Abierto (actualizado 2025)

A continuaciÃ³n se listan algunos de los LLMs open source mÃ¡s destacados y actualizados:

| Modelo           | Autor/OrganizaciÃ³n | TamaÃ±os Disponibles | VersiÃ³n Actual | Licencia      |
|------------------|--------------------|----------------------|----------------|----------------|
| **LLaMA**        | Meta               | 8B, 70B              | LLaMA 4        | Meta RAIL      |
| **Qwen**         | Alibaba            | 0.5B a 110B          | Qwen 2         | Apache 2.0     |
| **DeepSeek**     | DeepSeek AI        | 1.3B a 236B          | DeepSeek-V2    | MIT            |
| **Phi**          | Microsoft          | 3.8B, 7B             | Phi-3          | MIT            |
| **Gemma**        | Google             | 2B, 7B               | Gemma 1.1      | Apache 2.0     |
| **Mistral**      | Mistral AI         | 7B, Mixtral (12.7B MoE) | Mistral 7B / Mixtral 8x7B | Apache 2.0 |
| **Falcon**       | TII (UAE)          | 7B, 180B             | Falcon 180B    | Apache 2.0     |
| **Command-R**    | Cohere             | 35B                  | Command-R+     | RAIL           |

---

## ğŸ¤— Hugging Face

[Hugging Face](https://huggingface.co/) es una de las plataformas mÃ¡s influyentes en el ecosistema de inteligencia artificial moderna. Su propÃ³sito es democratizar el acceso a modelos de IA, datasets y herramientas para investigaciÃ³n, desarrollo y despliegue de soluciones basadas en machine learning.

**Â¿QuÃ© ofrece Hugging Face?**
- Un *hub centralizado* de modelos entrenados y datasets etiquetados.
- LibrerÃ­as como `transformers`, `datasets`, `peft`, `diffusers` y `evaluate`.
- Espacios (*Spaces*) para ejecutar y compartir demos interactivas.
- La Hugging Face Hub API para integrar modelos en producciÃ³n.
- Herramientas de fine-tuning, inferencia, cuantizaciÃ³n y mÃ¡s.
- Una comunidad colaborativa activa de investigadores, empresas y desarrolladores.

**Usos comunes:**
- Integrar LLMs como LLaMA, Mistral o Phi en apps.
- Entrenar modelos personalizados.
- Evaluar y comparar arquitecturas de IA.
- Desplegar servicios de inferencia desde Hugging Face Inference Endpoints.
- Explorar nuevos modelos generativos, como Diffusion Models para imagen y audio.

---

## ğŸ§° Ollama

[**Ollama**](https://ollama.com) es una herramienta sencilla para ejecutar modelos LLM localmente, con soporte para mÃºltiples modelos open-source preconfigurados.

### Requisitos

- macOS, Linux o Windows (con soporte WSL)
- Docker NO es necesario
- CPU moderna o GPU con soporte para aceleraciÃ³n (opcional)

### ğŸ“– DocumentaciÃ³n y APIs

- [GuÃ­a de la API de Ollama](../../wiki/ollama_api)  
- [SDK de Python para Ollama](../../wiki/ollama_python_sdk)
- [CreaciÃ³n y uso de Modelfile en Ollama](../../wiki/ollama_modelfile)

---

## ğŸ–¥ï¸ LM Studio

[LM Studio](https://lmstudio.ai/) es una aplicaciÃ³n de escritorio que permite interactuar con modelos de lenguaje de manera local y visual. Funciona como una interfaz grÃ¡fica para Ollama y llama.cpp, y estÃ¡ pensada para usuarios no tÃ©cnicos o que prefieren una experiencia similar a ChatGPT, pero con modelos locales.

**CaracterÃ­sticas destacadas:**
- Descargar y ejecutar modelos directamente desde la app.
- Soporte para mÃºltiples modelos open-source (LLaMA, Mistral, Phi, etc.).
- PersonalizaciÃ³n de temperatura, longitud de respuesta y formato.
- Compatible con macOS, Windows y Linux.

Ideal para experimentaciÃ³n, redacciÃ³n de contenido, aprendizaje y evaluaciÃ³n rÃ¡pida de modelos sin escribir cÃ³digo.

---

## ğŸ§© AnythingLLM

[AnythingLLM](https://anythingllm.com/) es una plataforma de cÃ³digo abierto que permite crear un **asistente privado impulsado por LLMs**, capaz de trabajar con tus propios datos, documentos y fuentes de conocimiento.  
[ğŸ™ GitHub Repository](https://github.com/Mintplex-Labs/anything-llm)

**Â¿QuÃ© puedes hacer con AnythingLLM?**
- Subir archivos (PDF, DOCX, TXT, etc.) y hacer preguntas sobre su contenido.
- Conectar fuentes externas como Notion, GitHub repos, sitios web y mÃ¡s.
- Utilizar diferentes backends como OpenAI, Ollama, Mistral, Hugging Face, entre otros.
- Desplegarlo en local, en servidores personales o en la nube.
- Administrar mÃºltiples espacios y usuarios con control de acceso.

Una soluciÃ³n ideal para construir un **chat corporativo privado**, motores de bÃºsqueda internos o asistentes personales de conocimiento con arquitectura plug-and-play.

---

## ğŸ“š Msty

[Msty](https://msty.app/) es una herramienta especializada en la **visualizaciÃ³n y anÃ¡lisis interno** de modelos de lenguaje.  
[ğŸ™ GitHub Repository](https://github.com/linonetwo/msty)

Te permite explorar:
- **Tokens** generados en cada paso
- **Embeddings** vectoriales y distancias semÃ¡nticas
- **Probabilidades de predicciÃ³n** token a token

Ideal para investigadores, educadores y quienes quieren entender cÃ³mo "piensa" un modelo. Msty puede ayudarte a explicar errores, mejorar prompts o hacer debugging de outputs inesperados.

---

## ğŸŒ Gradio

[Gradio](https://www.gradio.app/) es una librerÃ­a de Python que permite construir interfaces web para modelos de machine learning y deep learning en minutos. Ideal para prototipos, demos y validaciÃ³n con usuarios.

**Usos principales:**
- Crear formularios o chatbots con LLMs.
- Visualizar outputs de modelos de imagen, audio o NLP.
- Integrar con Hugging Face Spaces o notebooks.

Con unas pocas lÃ­neas de cÃ³digo puedes desplegar una interfaz intuitiva y compartible con cualquier persona.

---

## ğŸ”— Recursos adicionales

### ğŸ“š DocumentaciÃ³n y Comparativas
- [ğŸ“– DocumentaciÃ³n oficial de Ollama](https://ollama.com/library) â€“ Uso, modelos y configuraciÃ³n de Ollama.
- [ğŸ“Š Hugging Face Open LLM Leaderboard](https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard) â€“ Comparativa actualizada de modelos open-source.
- [ğŸ§  Awesome Open LLMs](https://github.com/Hannibal046/Awesome-LLMs) â€“ Lista curada de modelos, datasets y herramientas.
- [ğŸ§ª Hugging Face Hub](https://huggingface.co/models) â€“ Repositorio central de modelos preentrenados y datasets para IA generativa, NLP, visiÃ³n y mÃ¡s.

### âš™ï¸ Frameworks y LibrerÃ­as
- [ğŸ“¦ LlamaIndex](https://www.llamaindex.ai/) â€“ Framework para crear aplicaciones de RAG (Retrieval-Augmented Generation).
- [ğŸ” LangGraph](https://www.langgraph.dev/) â€“ Framework para flujos conversacionales multiestado con LLMs.
- [ğŸ§ª LangChain](https://www.langchain.com/) â€“ OrquestaciÃ³n de agentes y flujos con LLMs, APIs y herramientas externas.
- [ğŸ¤— Transformers (Hugging Face)](https://huggingface.co/docs/transformers/index) â€“ LibrerÃ­a para el uso de modelos de lenguaje en Python.

### ğŸ› ï¸ Herramientas Locales y UI
- [ğŸ–¥ï¸ LM Studio](https://lmstudio.ai/) â€“ Interfaz grÃ¡fica para descargar, ejecutar y chatear con LLMs localmente.
- [ğŸ§© EverythingLLM](https://github.com/Evanz111/EverythingLLM) â€“ Plataforma local y extensible para construir soluciones empresariales con LLMs.
- [ğŸŒ Gradio](https://www.gradio.app/) â€“ Crear interfaces web interactivas para modelos ML/LLM en minutos.
- [ğŸ“š Msty](https://github.com/linonetwo/msty) â€“ VisualizaciÃ³n y anÃ¡lisis de tokens, embeddings y procesos internos de los LLMs.
